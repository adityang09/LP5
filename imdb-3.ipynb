{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11699382,"sourceType":"datasetVersion","datasetId":7343389}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-06T11:06:54.018945Z","iopub.execute_input":"2025-05-06T11:06:54.019298Z","iopub.status.idle":"2025-05-06T11:06:54.506410Z","shell.execute_reply.started":"2025-05-06T11:06:54.019267Z","shell.execute_reply":"2025-05-06T11:06:54.505322Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/imdb-pict/IMDB Dataset.csv\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/input/imdb-pict/IMDB Dataset.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T11:06:54.508239Z","iopub.execute_input":"2025-05-06T11:06:54.508720Z","iopub.status.idle":"2025-05-06T11:06:56.311383Z","shell.execute_reply.started":"2025-05-06T11:06:54.508696Z","shell.execute_reply":"2025-05-06T11:06:56.310648Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T11:06:56.312449Z","iopub.execute_input":"2025-05-06T11:06:56.312803Z","iopub.status.idle":"2025-05-06T11:06:56.345342Z","shell.execute_reply.started":"2025-05-06T11:06:56.312775Z","shell.execute_reply":"2025-05-06T11:06:56.344149Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                                  review sentiment\n0      One of the other reviewers has mentioned that ...  positive\n1      A wonderful little production. <br /><br />The...  positive\n2      I thought this was a wonderful way to spend ti...  positive\n3      Basically there's a family where a little boy ...  negative\n4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n...                                                  ...       ...\n49995  I thought this movie did a down right good job...  positive\n49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n49997  I am a Catholic taught in parochial elementary...  negative\n49998  I'm going to have to disagree with the previou...  negative\n49999  No one expects the Star Trek movies to be high...  negative\n\n[50000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>One of the other reviewers has mentioned that ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I thought this was a wonderful way to spend ti...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Basically there's a family where a little boy ...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49995</th>\n      <td>I thought this movie did a down right good job...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>49996</th>\n      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>49997</th>\n      <td>I am a Catholic taught in parochial elementary...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>49998</th>\n      <td>I'm going to have to disagree with the previou...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>49999</th>\n      <td>No one expects the Star Trek movies to be high...</td>\n      <td>negative</td>\n    </tr>\n  </tbody>\n</table>\n<p>50000 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T11:06:56.348154Z","iopub.execute_input":"2025-05-06T11:06:56.348980Z","iopub.status.idle":"2025-05-06T11:06:56.374540Z","shell.execute_reply.started":"2025-05-06T11:06:56.348936Z","shell.execute_reply":"2025-05-06T11:06:56.373066Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"review       0\nsentiment    0\ndtype: int64"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T11:06:56.376690Z","iopub.execute_input":"2025-05-06T11:06:56.377566Z","iopub.status.idle":"2025-05-06T11:06:56.536029Z","shell.execute_reply.started":"2025-05-06T11:06:56.377535Z","shell.execute_reply":"2025-05-06T11:06:56.534993Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                                                   review sentiment\ncount                                               50000     50000\nunique                                              49582         2\ntop     Loved today's show!!! It was a variety and not...  positive\nfreq                                                    5     25000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>50000</td>\n      <td>50000</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>49582</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>Loved today's show!!! It was a variety and not...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>5</td>\n      <td>25000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"df['sentiment']=df['sentiment'].map({'positive':1,'negative':0})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T11:06:56.537091Z","iopub.execute_input":"2025-05-06T11:06:56.537406Z","iopub.status.idle":"2025-05-06T11:06:56.551665Z","shell.execute_reply.started":"2025-05-06T11:06:56.537387Z","shell.execute_reply":"2025-05-06T11:06:56.550340Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T11:06:56.552844Z","iopub.execute_input":"2025-05-06T11:06:56.553315Z","iopub.status.idle":"2025-05-06T11:06:56.581743Z","shell.execute_reply.started":"2025-05-06T11:06:56.553195Z","shell.execute_reply":"2025-05-06T11:06:56.580738Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                                                  review  sentiment\n0      One of the other reviewers has mentioned that ...          1\n1      A wonderful little production. <br /><br />The...          1\n2      I thought this was a wonderful way to spend ti...          1\n3      Basically there's a family where a little boy ...          0\n4      Petter Mattei's \"Love in the Time of Money\" is...          1\n...                                                  ...        ...\n49995  I thought this movie did a down right good job...          1\n49996  Bad plot, bad dialogue, bad acting, idiotic di...          0\n49997  I am a Catholic taught in parochial elementary...          0\n49998  I'm going to have to disagree with the previou...          0\n49999  No one expects the Star Trek movies to be high...          0\n\n[50000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>One of the other reviewers has mentioned that ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I thought this was a wonderful way to spend ti...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Basically there's a family where a little boy ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49995</th>\n      <td>I thought this movie did a down right good job...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>49996</th>\n      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>49997</th>\n      <td>I am a Catholic taught in parochial elementary...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>49998</th>\n      <td>I'm going to have to disagree with the previou...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>49999</th>\n      <td>No one expects the Star Trek movies to be high...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>50000 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T11:06:56.582686Z","iopub.execute_input":"2025-05-06T11:06:56.583017Z","iopub.status.idle":"2025-05-06T11:06:56.613132Z","shell.execute_reply.started":"2025-05-06T11:06:56.582985Z","shell.execute_reply":"2025-05-06T11:06:56.611958Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"review       0\nsentiment    0\ndtype: int64"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"import numpy as np\nreviews=(df['review']).astype(str).tolist()\nsetiments=(df['sentiment']).astype(int).tolist()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T11:06:56.614249Z","iopub.execute_input":"2025-05-06T11:06:56.614635Z","iopub.status.idle":"2025-05-06T11:06:56.647295Z","shell.execute_reply.started":"2025-05-06T11:06:56.614605Z","shell.execute_reply":"2025-05-06T11:06:56.646232Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T11:06:56.650833Z","iopub.execute_input":"2025-05-06T11:06:56.651131Z","iopub.status.idle":"2025-05-06T11:07:18.046191Z","shell.execute_reply.started":"2025-05-06T11:06:56.651110Z","shell.execute_reply":"2025-05-06T11:07:18.044947Z"}},"outputs":[{"name":"stderr","text":"2025-05-06 11:06:59.069576: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746529619.471422      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746529619.588601      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"df.dtypes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T11:07:18.048032Z","iopub.execute_input":"2025-05-06T11:07:18.049252Z","iopub.status.idle":"2025-05-06T11:07:18.057961Z","shell.execute_reply.started":"2025-05-06T11:07:18.049202Z","shell.execute_reply":"2025-05-06T11:07:18.056963Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"review       object\nsentiment     int64\ndtype: object"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"help(Tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T11:07:18.059009Z","iopub.execute_input":"2025-05-06T11:07:18.059371Z","iopub.status.idle":"2025-05-06T11:07:18.088621Z","shell.execute_reply.started":"2025-05-06T11:07:18.059340Z","shell.execute_reply":"2025-05-06T11:07:18.087460Z"}},"outputs":[{"name":"stdout","text":"Help on class Tokenizer in module keras.src.legacy.preprocessing.text:\n\nclass Tokenizer(builtins.object)\n |  Tokenizer(num_words=None, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ', char_level=False, oov_token=None, analyzer=None, **kwargs)\n |  \n |  DEPRECATED.\n |  \n |  Methods defined here:\n |  \n |  __init__(self, num_words=None, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ', char_level=False, oov_token=None, analyzer=None, **kwargs)\n |      Initialize self.  See help(type(self)) for accurate signature.\n |  \n |  fit_on_sequences(self, sequences)\n |  \n |  fit_on_texts(self, texts)\n |  \n |  get_config(self)\n |  \n |  sequences_to_matrix(self, sequences, mode='binary')\n |  \n |  sequences_to_texts(self, sequences)\n |  \n |  sequences_to_texts_generator(self, sequences)\n |  \n |  texts_to_matrix(self, texts, mode='binary')\n |  \n |  texts_to_sequences(self, texts)\n |  \n |  texts_to_sequences_generator(self, texts)\n |  \n |  to_json(self, **kwargs)\n |  \n |  ----------------------------------------------------------------------\n |  Data descriptors defined here:\n |  \n |  __dict__\n |      dictionary for instance variables\n |  \n |  __weakref__\n |      list of weak references to the object\n\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"tokenizer=Tokenizer(10000)\ntokenizer.fit_on_texts(reviews)\nseq=tokenizer.texts_to_sequences(reviews)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T11:07:18.089783Z","iopub.execute_input":"2025-05-06T11:07:18.090202Z","iopub.status.idle":"2025-05-06T11:07:35.570734Z","shell.execute_reply.started":"2025-05-06T11:07:18.090174Z","shell.execute_reply":"2025-05-06T11:07:35.569863Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"padded=pad_sequences(seq,maxlen=10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T11:07:35.571752Z","iopub.execute_input":"2025-05-06T11:07:35.572093Z","iopub.status.idle":"2025-05-06T11:07:35.741286Z","shell.execute_reply.started":"2025-05-06T11:07:35.572063Z","shell.execute_reply":"2025-05-06T11:07:35.740072Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"padded.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T11:07:35.742702Z","iopub.execute_input":"2025-05-06T11:07:35.743708Z","iopub.status.idle":"2025-05-06T11:07:35.753028Z","shell.execute_reply.started":"2025-05-06T11:07:35.743667Z","shell.execute_reply":"2025-05-06T11:07:35.751783Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"(50000, 10)"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"X=np.array(padded)\nY=np.array(setiments)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T11:07:35.753722Z","iopub.execute_input":"2025-05-06T11:07:35.754038Z","iopub.status.idle":"2025-05-06T11:07:35.780723Z","shell.execute_reply.started":"2025-05-06T11:07:35.754012Z","shell.execute_reply":"2025-05-06T11:07:35.779576Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T11:07:35.781892Z","iopub.execute_input":"2025-05-06T11:07:35.782241Z","iopub.status.idle":"2025-05-06T11:07:36.492713Z","shell.execute_reply.started":"2025-05-06T11:07:35.782216Z","shell.execute_reply":"2025-05-06T11:07:36.491174Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding,Dense,Flatten","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T11:07:36.494057Z","iopub.execute_input":"2025-05-06T11:07:36.494746Z","iopub.status.idle":"2025-05-06T11:07:36.505167Z","shell.execute_reply.started":"2025-05-06T11:07:36.494720Z","shell.execute_reply":"2025-05-06T11:07:36.504052Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"model=Sequential()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T11:07:36.506552Z","iopub.execute_input":"2025-05-06T11:07:36.506809Z","iopub.status.idle":"2025-05-06T11:07:36.537867Z","shell.execute_reply.started":"2025-05-06T11:07:36.506791Z","shell.execute_reply":"2025-05-06T11:07:36.536060Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"\nmodel.add(Embedding(10000,128,input_length=100))\nmodel.add(Flatten())\nmodel.add(Dense(10,activation='relu'))\nmodel.add(Dense(1,activation='sigmoid'))\nmodel.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T11:29:48.610704Z","iopub.execute_input":"2025-05-06T11:29:48.611063Z","iopub.status.idle":"2025-05-06T11:29:48.682490Z","shell.execute_reply.started":"2025-05-06T11:29:48.611043Z","shell.execute_reply":"2025-05-06T11:29:48.681584Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"model.fit(X_train,Y_train,epochs=5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T11:29:50.478604Z","iopub.execute_input":"2025-05-06T11:29:50.479376Z","iopub.status.idle":"2025-05-06T11:31:01.857043Z","shell.execute_reply.started":"2025-05-06T11:29:50.479351Z","shell.execute_reply":"2025-05-06T11:31:01.855686Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/5\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/base_optimizer.py:678: UserWarning: Gradients do not exist for variables ['embeddings', 'kernel', 'bias', 'kernel', 'bias', 'embeddings', 'kernel', 'bias', 'kernel', 'bias'] when minimizing the loss. If using `model.compile()`, did you forget to provide a `loss` argument?\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - accuracy: 0.5001 - loss: 0.6932\nEpoch 2/5\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 12ms/step - accuracy: 0.4963 - loss: 0.6932\nEpoch 3/5\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - accuracy: 0.5002 - loss: 0.6932\nEpoch 4/5\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - accuracy: 0.5028 - loss: 0.6931\nEpoch 5/5\n\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - accuracy: 0.5022 - loss: 0.6932\n","output_type":"stream"},{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7f0338d5c290>"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"model.evaluate(X_test,Y_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T11:31:01.859177Z","iopub.execute_input":"2025-05-06T11:31:01.859599Z","iopub.status.idle":"2025-05-06T11:31:03.150450Z","shell.execute_reply.started":"2025-05-06T11:31:01.859565Z","shell.execute_reply":"2025-05-06T11:31:03.148940Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4875 - loss: 0.6933\n","output_type":"stream"},{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"[0.6932598352432251, 0.4936000108718872]"},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"X_test.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T11:37:21.949787Z","iopub.execute_input":"2025-05-06T11:37:21.950124Z","iopub.status.idle":"2025-05-06T11:37:21.956859Z","shell.execute_reply.started":"2025-05-06T11:37:21.950102Z","shell.execute_reply":"2025-05-06T11:37:21.955856Z"}},"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"(10000, 10)"},"metadata":{}}],"execution_count":42},{"cell_type":"code","source":"help(Embedding)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T11:29:13.230937Z","iopub.execute_input":"2025-05-06T11:29:13.232062Z","iopub.status.idle":"2025-05-06T11:29:13.246038Z","shell.execute_reply.started":"2025-05-06T11:29:13.232030Z","shell.execute_reply":"2025-05-06T11:29:13.244915Z"}},"outputs":[{"name":"stdout","text":"Help on class Embedding in module keras.src.layers.core.embedding:\n\nclass Embedding(keras.src.layers.layer.Layer)\n |  Embedding(input_dim, output_dim, embeddings_initializer='uniform', embeddings_regularizer=None, embeddings_constraint=None, mask_zero=False, weights=None, lora_rank=None, **kwargs)\n |  \n |  Turns positive integers (indexes) into dense vectors of fixed size.\n |  \n |  e.g. `[[4], [20]] -> [[0.25, 0.1], [0.6, -0.2]]`\n |  \n |  This layer can only be used on positive integer inputs of a fixed range.\n |  \n |  Example:\n |  \n |  >>> model = keras.Sequential()\n |  >>> model.add(keras.layers.Embedding(1000, 64))\n |  >>> # The model will take as input an integer matrix of size (batch,\n |  >>> # input_length), and the largest integer (i.e. word index) in the input\n |  >>> # should be no larger than 999 (vocabulary size).\n |  >>> # Now model.output_shape is (None, 10, 64), where `None` is the batch\n |  >>> # dimension.\n |  >>> input_array = np.random.randint(1000, size=(32, 10))\n |  >>> model.compile('rmsprop', 'mse')\n |  >>> output_array = model.predict(input_array)\n |  >>> print(output_array.shape)\n |  (32, 10, 64)\n |  \n |  Args:\n |      input_dim: Integer. Size of the vocabulary,\n |          i.e. maximum integer index + 1.\n |      output_dim: Integer. Dimension of the dense embedding.\n |      embeddings_initializer: Initializer for the `embeddings`\n |          matrix (see `keras.initializers`).\n |      embeddings_regularizer: Regularizer function applied to\n |          the `embeddings` matrix (see `keras.regularizers`).\n |      embeddings_constraint: Constraint function applied to\n |          the `embeddings` matrix (see `keras.constraints`).\n |      mask_zero: Boolean, whether or not the input value 0 is a special\n |          \"padding\" value that should be masked out.\n |          This is useful when using recurrent layers which\n |          may take variable length input. If this is `True`,\n |          then all subsequent layers in the model need\n |          to support masking or an exception will be raised.\n |          If `mask_zero` is set to `True`, as a consequence,\n |          index 0 cannot be used in the vocabulary (`input_dim` should\n |          equal size of vocabulary + 1).\n |      weights: Optional floating-point matrix of size\n |          `(input_dim, output_dim)`. The initial embeddings values\n |          to use.\n |      lora_rank: Optional integer. If set, the layer's forward pass\n |          will implement LoRA (Low-Rank Adaptation)\n |          with the provided rank. LoRA sets the layer's embeddings\n |          matrix to non-trainable and replaces it with a delta over the\n |          original matrix, obtained via multiplying two lower-rank\n |          trainable matrices. This can be useful to reduce the\n |          computation cost of fine-tuning large embedding layers.\n |          You can also enable LoRA on an existing\n |          `Embedding` layer by calling `layer.enable_lora(rank)`.\n |  \n |  Input shape:\n |      2D tensor with shape: `(batch_size, input_length)`.\n |  \n |  Output shape:\n |      3D tensor with shape: `(batch_size, input_length, output_dim)`.\n |  \n |  Method resolution order:\n |      Embedding\n |      keras.src.layers.layer.Layer\n |      keras.src.backend.tensorflow.layer.TFLayer\n |      keras.src.backend.tensorflow.trackable.KerasAutoTrackable\n |      tensorflow.python.trackable.autotrackable.AutoTrackable\n |      tensorflow.python.trackable.base.Trackable\n |      keras.src.ops.operation.Operation\n |      keras.src.saving.keras_saveable.KerasSaveable\n |      builtins.object\n |  \n |  Methods defined here:\n |  \n |  __init__(self, input_dim, output_dim, embeddings_initializer='uniform', embeddings_regularizer=None, embeddings_constraint=None, mask_zero=False, weights=None, lora_rank=None, **kwargs)\n |      Initialize self.  See help(type(self)) for accurate signature.\n |  \n |  build(self, input_shape=None)\n |  \n |  call(self, inputs)\n |  \n |  compute_mask(self, inputs, mask=None)\n |  \n |  compute_output_shape(self, input_shape)\n |  \n |  enable_lora(self, rank, a_initializer='he_uniform', b_initializer='zeros')\n |  \n |  get_config(self)\n |      Returns the config of the object.\n |      \n |      An object config is a Python dictionary (serializable)\n |      containing the information needed to re-instantiate it.\n |  \n |  load_own_variables(self, store)\n |      Loads the state of the layer.\n |      \n |      You can override this method to take full control of how the state of\n |      the layer is loaded upon calling `keras.models.load_model()`.\n |      \n |      Args:\n |          store: Dict from which the state of the model will be loaded.\n |  \n |  quantize(self, mode, type_check=True)\n |  \n |  quantized_build(self, input_shape, mode)\n |  \n |  quantized_call(self, *args, **kwargs)\n |  \n |  save_own_variables(self, store)\n |      Saves the state of the layer.\n |      \n |      You can override this method to take full control of how the state of\n |      the layer is saved upon calling `model.save()`.\n |      \n |      Args:\n |          store: Dict where the state of the model will be saved.\n |  \n |  ----------------------------------------------------------------------\n |  Readonly properties defined here:\n |  \n |  embeddings\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes defined here:\n |  \n |  __annotations__ = {}\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from keras.src.layers.layer.Layer:\n |  \n |  __call__(self, *args, **kwargs)\n |      Call self as a function.\n |  \n |  __delattr__(self, name)\n |      Implement delattr(self, name).\n |  \n |  __repr__(self)\n |      Return repr(self).\n |  \n |  __setattr__(self, name, value)\n |      Support self.foo = trackable syntax.\n |  \n |  __str__(self)\n |      Return str(self).\n |  \n |  add_loss(self, loss)\n |      Can be called inside of the `call()` method to add a scalar loss.\n |      \n |      Example:\n |      \n |      ```python\n |      class MyLayer(Layer):\n |          ...\n |          def call(self, x):\n |              self.add_loss(ops.sum(x))\n |              return x\n |      ```\n |  \n |  add_metric(self, *args, **kwargs)\n |  \n |  add_variable(self, shape, initializer, dtype=None, trainable=True, autocast=True, regularizer=None, constraint=None, name=None)\n |      Add a weight variable to the layer.\n |      \n |      Alias of `add_weight()`.\n |  \n |  add_weight(self, shape=None, initializer=None, dtype=None, trainable=True, autocast=True, regularizer=None, constraint=None, aggregation='mean', name=None)\n |      Add a weight variable to the layer.\n |      \n |      Args:\n |          shape: Shape tuple for the variable. Must be fully-defined\n |              (no `None` entries). Defaults to `()` (scalar) if unspecified.\n |          initializer: Initializer object to use to populate the initial\n |              variable value, or string name of a built-in initializer\n |              (e.g. `\"random_normal\"`). If unspecified, defaults to\n |              `\"glorot_uniform\"` for floating-point variables and to `\"zeros\"`\n |              for all other types (e.g. int, bool).\n |          dtype: Dtype of the variable to create, e.g. `\"float32\"`. If\n |              unspecified, defaults to the layer's variable dtype\n |              (which itself defaults to `\"float32\"` if unspecified).\n |          trainable: Boolean, whether the variable should be trainable via\n |              backprop or whether its updates are managed manually. Defaults\n |              to `True`.\n |          autocast: Boolean, whether to autocast layers variables when\n |              accessing them. Defaults to `True`.\n |          regularizer: Regularizer object to call to apply penalty on the\n |              weight. These penalties are summed into the loss function\n |              during optimization. Defaults to `None`.\n |          constraint: Contrainst object to call on the variable after any\n |              optimizer update, or string name of a built-in constraint.\n |              Defaults to `None`.\n |          aggregation: String, one of `'mean'`, `'sum'`,\n |              `'only_first_replica'`. Annotates the variable with the type\n |              of multi-replica aggregation to be used for this variable\n |              when writing custom data parallel training loops.\n |          name: String name of the variable. Useful for debugging purposes.\n |  \n |  build_from_config(self, config)\n |      Builds the layer's states with the supplied config dict.\n |      \n |      By default, this method calls the `build(config[\"input_shape\"])` method,\n |      which creates weights based on the layer's input shape in the supplied\n |      config. If your config contains other information needed to load the\n |      layer's state, you should override this method.\n |      \n |      Args:\n |          config: Dict containing the input shape associated with this layer.\n |  \n |  compute_output_spec(self, *args, **kwargs)\n |  \n |  count_params(self)\n |      Count the total number of scalars composing the weights.\n |      \n |      Returns:\n |          An integer count.\n |  \n |  get_build_config(self)\n |      Returns a dictionary with the layer's input shape.\n |      \n |      This method returns a config dict that can be used by\n |      `build_from_config(config)` to create all states (e.g. Variables and\n |      Lookup tables) needed by the layer.\n |      \n |      By default, the config only contains the input shape that the layer\n |      was built with. If you're writing a custom layer that creates state in\n |      an unusual way, you should override this method to make sure this state\n |      is already created when Keras attempts to load its value upon model\n |      loading.\n |      \n |      Returns:\n |          A dict containing the input shape associated with the layer.\n |  \n |  get_weights(self)\n |      Return the values of `layer.weights` as a list of NumPy arrays.\n |  \n |  set_weights(self, weights)\n |      Sets the values of `layer.weights` from a list of NumPy arrays.\n |  \n |  stateless_call(self, trainable_variables, non_trainable_variables, *args, return_losses=False, **kwargs)\n |      Call the layer without any side effects.\n |      \n |      Args:\n |          trainable_variables: List of trainable variables of the model.\n |          non_trainable_variables: List of non-trainable variables of the\n |              model.\n |          *args: Positional arguments to be passed to `call()`.\n |          return_losses: If `True`, `stateless_call()` will return the list of\n |              losses created during `call()` as part of its return values.\n |          **kwargs: Keyword arguments to be passed to `call()`.\n |      \n |      Returns:\n |          A tuple. By default, returns `(outputs, non_trainable_variables)`.\n |              If `return_losses = True`, then returns\n |              `(outputs, non_trainable_variables, losses)`.\n |      \n |      Note: `non_trainable_variables` include not only non-trainable weights\n |      such as `BatchNormalization` statistics, but also RNG seed state\n |      (if there are any random operations part of the layer, such as dropout),\n |      and `Metric` state (if there are any metrics attached to the layer).\n |      These are all elements of state of the layer.\n |      \n |      Example:\n |      \n |      ```python\n |      model = ...\n |      data = ...\n |      trainable_variables = model.trainable_variables\n |      non_trainable_variables = model.non_trainable_variables\n |      # Call the model with zero side effects\n |      outputs, non_trainable_variables = model.stateless_call(\n |          trainable_variables,\n |          non_trainable_variables,\n |          data,\n |      )\n |      # Attach the updated state to the model\n |      # (until you do this, the model is still in its pre-call state).\n |      for ref_var, value in zip(\n |          model.non_trainable_variables, non_trainable_variables\n |      ):\n |          ref_var.assign(value)\n |      ```\n |  \n |  ----------------------------------------------------------------------\n |  Static methods inherited from keras.src.layers.layer.Layer:\n |  \n |  __new__(cls, *args, **kwargs)\n |      Create and return a new object.  See help(type) for accurate signature.\n |  \n |  ----------------------------------------------------------------------\n |  Readonly properties inherited from keras.src.layers.layer.Layer:\n |  \n |  compute_dtype\n |      The dtype of the computations performed by the layer.\n |  \n |  dtype\n |      Alias of `layer.variable_dtype`.\n |  \n |  input_dtype\n |      The dtype layer inputs should be converted to.\n |  \n |  losses\n |      List of scalar losses from `add_loss`, regularizers and sublayers.\n |  \n |  metrics\n |      List of all metrics.\n |  \n |  metrics_variables\n |      List of all metric variables.\n |  \n |  non_trainable_variables\n |      List of all non-trainable layer state.\n |      \n |      This extends `layer.non_trainable_weights` to include all state used by\n |      the layer including state for metrics and `SeedGenerator`s.\n |  \n |  non_trainable_weights\n |      List of all non-trainable weight variables of the layer.\n |      \n |      These are the weights that should not be updated by the optimizer during\n |      training. Unlike, `layer.non_trainable_variables` this excludes metric\n |      state and random seeds.\n |  \n |  path\n |      The path of the layer.\n |      \n |      If the layer has not been built yet, it will be `None`.\n |  \n |  quantization_mode\n |      The quantization mode of this layer, `None` if not quantized.\n |  \n |  trainable_variables\n |      List of all trainable layer state.\n |      \n |      This is equivalent to `layer.trainable_weights`.\n |  \n |  trainable_weights\n |      List of all trainable weight variables of the layer.\n |      \n |      These are the weights that get updated by the optimizer during training.\n |  \n |  variable_dtype\n |      The dtype of the state (weights) of the layer.\n |  \n |  variables\n |      List of all layer state, including random seeds.\n |      \n |      This extends `layer.weights` to include all state used by the layer\n |      including `SeedGenerator`s.\n |      \n |      Note that metrics variables are not included here, use\n |      `metrics_variables` to visit all the metric variables.\n |  \n |  weights\n |      List of all weight variables of the layer.\n |      \n |      Unlike, `layer.variables` this excludes metric state and random seeds.\n |  \n |  ----------------------------------------------------------------------\n |  Data descriptors inherited from keras.src.layers.layer.Layer:\n |  \n |  dtype_policy\n |  \n |  input_spec\n |  \n |  supports_masking\n |      Whether this layer supports computing a mask using `compute_mask`.\n |  \n |  trainable\n |      Settable boolean, whether this layer should be trainable or not.\n |  \n |  ----------------------------------------------------------------------\n |  Data descriptors inherited from tensorflow.python.trackable.base.Trackable:\n |  \n |  __dict__\n |      dictionary for instance variables\n |  \n |  __weakref__\n |      list of weak references to the object\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from keras.src.ops.operation.Operation:\n |  \n |  symbolic_call(self, *args, **kwargs)\n |  \n |  ----------------------------------------------------------------------\n |  Class methods inherited from keras.src.ops.operation.Operation:\n |  \n |  from_config(config)\n |      Creates an operation from its config.\n |      \n |      This method is the reverse of `get_config`, capable of instantiating the\n |      same operation from the config dictionary.\n |      \n |      Note: If you override this method, you might receive a serialized dtype\n |      config, which is a `dict`. You can deserialize it as follows:\n |      \n |      ```python\n |      if \"dtype\" in config and isinstance(config[\"dtype\"], dict):\n |          policy = dtype_policies.deserialize(config[\"dtype\"])\n |      ```\n |      \n |      Args:\n |          config: A Python dictionary, typically the output of `get_config`.\n |      \n |      Returns:\n |          An operation instance.\n |  \n |  ----------------------------------------------------------------------\n |  Readonly properties inherited from keras.src.ops.operation.Operation:\n |  \n |  input\n |      Retrieves the input tensor(s) of a symbolic operation.\n |      \n |      Only returns the tensor(s) corresponding to the *first time*\n |      the operation was called.\n |      \n |      Returns:\n |          Input tensor or list of input tensors.\n |  \n |  output\n |      Retrieves the output tensor(s) of a layer.\n |      \n |      Only returns the tensor(s) corresponding to the *first time*\n |      the operation was called.\n |      \n |      Returns:\n |          Output tensor or list of output tensors.\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from keras.src.saving.keras_saveable.KerasSaveable:\n |  \n |  __reduce__(self)\n |      __reduce__ is used to customize the behavior of `pickle.pickle()`.\n |      \n |      The method returns a tuple of two elements: a function, and a list of\n |      arguments to pass to that function.  In this case we just leverage the\n |      keras saving library.\n\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}